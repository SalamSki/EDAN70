{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "Imports and define names of datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:02:45.075847Z",
     "iopub.status.busy": "2024-11-16T01:02:45.075725Z",
     "iopub.status.idle": "2024-11-16T01:03:04.070511Z",
     "shell.execute_reply": "2024-11-16T01:03:04.069918Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List,Tuple\n",
    "from tqdm import tqdm  \n",
    "import regex as re\n",
    "import random\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "datafiles= {\n",
    "  \"E1\" : [''],\n",
    "  \"E2\" : ['a', 'b'],\n",
    "  \"E3\" : [''],\n",
    "  \"E4\" : ['']\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that extracts headwords out of \\<b\\> tags to build a headword dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.072450Z",
     "iopub.status.busy": "2024-11-16T01:03:04.072169Z",
     "iopub.status.idle": "2024-11-16T01:03:04.076453Z",
     "shell.execute_reply": "2024-11-16T01:03:04.076091Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_b_tag_dataset(datastring, next_chars = 500, verbose=False):\n",
    "  b_tag_dict = []\n",
    "\n",
    "  # BUILD POSITIVE \n",
    "  for match in tqdm(re.finditer(r\"((?<=<b>).+<\\/b>)(.*(?<=<b>).+<\\/b>)*\", datastring), disable=(not verbose)):\n",
    "    g1 = match.group(0)\n",
    "    matched_b_tag = re.sub(r\"</b>.*<b>|</b>\",\" \",g1).strip()\n",
    "    end_of_b_tag = match.end()  \n",
    "    \n",
    "    surrounding_text_match = re.search(r\"([^<]{1,\"+str(next_chars)+r\"})(?=<|$)\", datastring[end_of_b_tag:end_of_b_tag+next_chars])\n",
    "    surrounding_text = surrounding_text_match.group(0) if surrounding_text_match else \"\"\n",
    "\n",
    "    short_def = re.sub(r\"\\s+\", \" \", surrounding_text).strip()\n",
    "    if len(short_def) > 0:\n",
    "      b_tag_dict.append([f\"{matched_b_tag} {short_def}\", matched_b_tag])\n",
    "\n",
    "  # BUILD NEGATIVE\n",
    "  for match in tqdm(re.finditer(r\"(\\n\\n\\p{Upper}[^<]{10,500})(?=\\n|$|<)\", datastring), disable=(not verbose)):\n",
    "    g = match.group(0)\n",
    "    matched_text = re.sub(r\"\\s+\", \" \", g).strip()\n",
    "    b_tag_dict.append([matched_text, \"<NO_HEADWORD>\"])\n",
    "\n",
    "  return b_tag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the headword datasets for the first and second editions (E1 \\& E2) where for each entry there is:\n",
    "  - Feature: A paragraph or piece of text that starts with a headword, followed by up to <i>next_chars</i> number of characters, default is 500.\n",
    "  - label: The headword at the beginning of the corresponding feature, empty string if feature wasn't a <i>\"headword\"</i> paragraph.\n",
    "\n",
    "Save results to json files:\n",
    "```json\n",
    "  [\"Lund, uppstad i Malmöhus län...beskaffenhet. I all\", \"Lund,\"]\n",
    "  [\"betjenade sig af rapporter från...till privatlifvet\", \"\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.077819Z",
     "iopub.status.busy": "2024-11-16T01:03:04.077689Z",
     "iopub.status.idle": "2024-11-16T01:03:04.079708Z",
     "shell.execute_reply": "2024-11-16T01:03:04.079366Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i,edition in enumerate(['E1', 'E2']):\n",
    "\n",
    "#   dataset = \"\"\n",
    "#   for file in datafiles.get(edition):\n",
    "#     with open(f\"./dataset/NF_{edition}{file}.txt\", \"r\", encoding='utf-8') as fr:\n",
    "#       dataset += fr.read()\n",
    "#       fr.close()\n",
    "      \n",
    "#   b_tag_dict = build_b_tag_dataset(dataset, verbose=True)\n",
    "#   print(f\"{edition} has {len(b_tag_dict):,} entries\")\n",
    "\n",
    "#   with open(f\"./dataset/NF_{edition}_B.json\", \"w\") as b_json:\n",
    "#     json.dump(b_tag_dict, b_json, indent=2, ensure_ascii=False)\n",
    "# del i, edition, dataset, file, fr, b_tag_dict, b_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.080940Z",
     "iopub.status.busy": "2024-11-16T01:03:04.080815Z",
     "iopub.status.idle": "2024-11-16T01:03:04.524910Z",
     "shell.execute_reply": "2024-11-16T01:03:04.524362Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"KB/bert-base-swedish-cased\")\n",
    "#_ = tokenizer.add_tokens([\"<NO_HEADWORD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.526659Z",
     "iopub.status.busy": "2024-11-16T01:03:04.526523Z",
     "iopub.status.idle": "2024-11-16T01:05:47.982547Z",
     "shell.execute_reply": "2024-11-16T01:05:47.981956Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i, edition in enumerate(['E1', 'E2']):\n",
    "  for file in datafiles.get(edition):\n",
    "    with open(f\"./dataset/NF_{edition}_B.json\", \"r\", encoding='utf-8') as b_json:\n",
    "      dataset += json.load(b_json)\n",
    "      b_json.close()\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "def process_data(sentence, headword):\n",
    "    encoded_sentence = tokenizer(\n",
    "        sentence,\n",
    "        add_special_tokens=True, # Add [CLS] and [SEP] tokens\n",
    "        padding='max_length',   # Pad to a maximum length\n",
    "        max_length=100,        # Choose an appropriate max length\n",
    "        truncation=True,        # Truncate if longer than max length\n",
    "        return_tensors='pt'   # Return PyTorch tensors\n",
    "    )\n",
    "    # Encode the headword\n",
    "    encoded_headword = tokenizer(\n",
    "        headword,\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        max_length=20,           # Choose a suitable max length for headwords\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoded_sentence['input_ids'][0], encoded_headword['input_ids'][0]\n",
    "\n",
    "def extract_features_labels(dataset) -> Tuple[List, List]:\n",
    "    x = []\n",
    "    y = []\n",
    "    for entry in tqdm(dataset):\n",
    "      s, h = process_data(entry[0], entry[1])\n",
    "      x.append(s)\n",
    "      y.append(h)\n",
    "    #return x,y\n",
    "    return torch.stack(x).to(device), torch.stack(y).to(device)\n",
    "\n",
    "#dataset = dataset[:int(0.2*len(dataset))]\n",
    "X, y = extract_features_labels(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:47.986360Z",
     "iopub.status.busy": "2024-11-16T01:05:47.986218Z",
     "iopub.status.idle": "2024-11-16T01:05:48.146526Z",
     "shell.execute_reply": "2024-11-16T01:05:48.145965Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "print(X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:48.148094Z",
     "iopub.status.busy": "2024-11-16T01:05:48.147931Z",
     "iopub.status.idle": "2024-11-16T01:05:48.228501Z",
     "shell.execute_reply": "2024-11-16T01:05:48.228100Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Max input ID:\", torch.max(X_train))\n",
    "print(\"Max target ID:\", torch.max(y_train))\n",
    "#tokenizer.convert_tokens_to_ids('<NO_HEADWORD>')\n",
    "print(tokenizer.convert_ids_to_tokens(50325))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:48.229911Z",
     "iopub.status.busy": "2024-11-16T01:05:48.229771Z",
     "iopub.status.idle": "2024-11-16T01:05:48.235173Z",
     "shell.execute_reply": "2024-11-16T01:05:48.234781Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "class HeadwordPredictorLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, tokenizer, max_length=20): # add max_length\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, target_seq=None, teacher_forcing_ratio=0.5):\n",
    "        batch_size = input_seq.size(0)\n",
    "        input_embeddings = self.embedding(input_seq)\n",
    "        _, (hidden, cell) = self.encoder(input_embeddings)\n",
    "\n",
    "\n",
    "        decoder_hidden = hidden\n",
    "        decoder_cell = cell\n",
    "\n",
    "        target_length = target_seq.size(1) if target_seq is not None else self.max_length\n",
    "\n",
    "        outputs = torch.zeros(batch_size, target_length, vocab_size).to(input_seq.device)\n",
    "\n",
    "        decoder_input = torch.full((batch_size, 1), self.tokenizer.cls_token_id, dtype=torch.long).to(input_seq.device)\n",
    "\n",
    "        for t in range(target_length):\n",
    "          #print(decoder_input.shape)\n",
    "          decoder_embeddings = self.embedding(decoder_input)\n",
    "          decoder_output, (decoder_hidden, decoder_cell) = self.decoder(decoder_embeddings, (decoder_hidden, decoder_cell))\n",
    "\n",
    "          output = self.fc(decoder_output)\n",
    "          outputs[:, t:t+1, :] = output\n",
    "\n",
    "          use_teacher_forcing = torch.rand(1) < teacher_forcing_ratio if target_seq is not None else False\n",
    "\n",
    "          if use_teacher_forcing:\n",
    "              decoder_input = target_seq[:, t:t+1].long()\n",
    "\n",
    "          else:\n",
    "\n",
    "              top1 = output.argmax(2)\n",
    "              decoder_input = top1\n",
    "\n",
    "\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:48.236441Z",
     "iopub.status.busy": "2024-11-16T01:05:48.236313Z",
     "iopub.status.idle": "2024-11-16T01:05:48.245779Z",
     "shell.execute_reply": "2024-11-16T01:05:48.245190Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:48.247056Z",
     "iopub.status.busy": "2024-11-16T01:05:48.246936Z",
     "iopub.status.idle": "2024-11-16T01:05:48.249337Z",
     "shell.execute_reply": "2024-11-16T01:05:48.248989Z"
    }
   },
   "outputs": [],
   "source": [
    "#print tokenid 0-4\n",
    "print(tokenizer.decode([0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:48.250602Z",
     "iopub.status.busy": "2024-11-16T01:05:48.250485Z",
     "iopub.status.idle": "2024-11-16T01:05:53.053539Z",
     "shell.execute_reply": "2024-11-16T01:05:53.052996Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "max_length = 20\n",
    "\n",
    "model = HeadwordPredictorLSTM(vocab_size, embedding_dim, hidden_dim, tokenizer, max_length).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:53.055633Z",
     "iopub.status.busy": "2024-11-16T01:05:53.055402Z",
     "iopub.status.idle": "2024-11-16T01:05:53.058296Z",
     "shell.execute_reply": "2024-11-16T01:05:53.057940Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train.long(), y_train.long())\n",
    "test_dataset = TensorDataset(X_test.long(), y_test.long())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:53.059703Z",
     "iopub.status.busy": "2024-11-16T01:05:53.059421Z",
     "iopub.status.idle": "2024-11-16T04:02:51.483030Z",
     "shell.execute_reply": "2024-11-16T04:02:51.482555Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for input_batch, target_batch in (train_loader):\n",
    "        input_batch = input_batch#.to(device)\n",
    "        target_batch = target_batch#.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_batch, target_batch, teacher_forcing_ratio=0.5)\n",
    "        #print(outputs.shape)\n",
    "        #print(target_batch.shape)\n",
    "        #print(outputs.view(-1, vocab_size).shape)\n",
    "        #print(target_batch.view(-1).shape)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), target_batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "\n",
    "        for input_batch, target_batch in tqdm(test_loader, desc = \"Testing\"):\n",
    "          input_batch = input_batch#.to(device)\n",
    "          target_batch = target_batch#.to(device)\n",
    "\n",
    "          outputs = model(input_batch, target_batch, teacher_forcing_ratio=0)\n",
    "\n",
    "          loss = criterion(outputs.view(-1, vocab_size), target_batch.view(-1))\n",
    "\n",
    "          test_loss += loss.item()\n",
    "\n",
    "    avg_test_loss = test_loss/len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T04:02:51.484972Z",
     "iopub.status.busy": "2024-11-16T04:02:51.484820Z",
     "iopub.status.idle": "2024-11-16T04:02:51.586294Z",
     "shell.execute_reply": "2024-11-16T04:02:51.585934Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "input_sentence = \"En stad i skåne\"\n",
    "encoded_input = tokenizer(input_sentence, return_tensors=\"pt\", padding = \"max_length\", max_length = 128, truncation = True).to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(encoded_input['input_ids'])\n",
    "\n",
    "\n",
    "predicted_indices = output.argmax(2)[0].cpu().tolist()\n",
    "predicted_headword = tokenizer.decode(predicted_indices, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(\"Predicted headword:\", predicted_headword)\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(),\"headword_predictor.pth\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
