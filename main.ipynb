{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Detecting, Matching, and Linking. \n",
    "\n",
    "### Authors: Albin Andersson, Salam Jonasson, Fredrik Wastring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Imports and define names of datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:02:45.075847Z",
     "iopub.status.busy": "2024-11-16T01:02:45.075725Z",
     "iopub.status.idle": "2024-11-16T01:03:04.070511Z",
     "shell.execute_reply": "2024-11-16T01:03:04.069918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  \n",
    "from typing import List,Tuple\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "datafiles= {\n",
    "  \"E1\" : [''],\n",
    "  \"E2\" : ['a', 'b'],\n",
    "  \"E3\" : [''],\n",
    "  \"E4\" : ['']\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headword Extraction\n",
    "\n",
    "## Dataset Preparation \n",
    "Build the headword training set if ```SHOULD_BUILD_HEADWORD_SET``` is ```True```, toggle off this boolean if you have at least built once:\n",
    "\n",
    "  * Use the first and second editions ([E1](./dataset/clear_text/NF_E1.txt) \\& [E2](./dataset/clear_text/NF_E2a.txt)) where for each entry there is:\n",
    "    - Feature: A paragraph or piece of text that starts with a headword, followed by up to <i>next_chars</i> number of characters, default is 500.\n",
    "    - label: The headword at the beginning of the corresponding feature, empty string if feature wasn't a <i>\"headword\"</i> paragraph.\n",
    "\n",
    "    Save results to [train_set.json](./dataset/headword/train_set.json):\n",
    "    ```json\n",
    "      [\"Lund, uppstad i Malmöhus län...beskaffenhet. I all\", \"Lund,\"]\n",
    "      [\"betjenade sig af rapporter från...till privatlifvet\", \"\"]\n",
    "    ```\n",
    "\n",
    "We also load in the manually annotated test set  from the json file [test_set.json](./dataset/headword/test_set.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.077819Z",
     "iopub.status.busy": "2024-11-16T01:03:04.077689Z",
     "iopub.status.idle": "2024-11-16T01:03:04.079708Z",
     "shell.execute_reply": "2024-11-16T01:03:04.079366Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_json_headword_set():\n",
    "  def extract_b_tags(datastring, next_chars = 500, verbose=False):\n",
    "    b_tag_dict = []\n",
    "\n",
    "    # BUILD POSITIVE \n",
    "    for match in tqdm(re.finditer(r\"((?<=<b>).+<\\/b>)(.*(?<=<b>).+<\\/b>)*\", datastring), disable=(not verbose), desc=\"Positives\"):\n",
    "      g1 = match.group(0)\n",
    "      matched_b_tag = re.sub(r\"</b>.*<b>|</b>\",\" \",g1).strip()\n",
    "      end_of_b_tag = match.end()  \n",
    "      \n",
    "      surrounding_text_match = re.search(r\"([^<]{1,\"+str(next_chars)+r\"})(?=<|$)\", datastring[end_of_b_tag:end_of_b_tag+next_chars])\n",
    "      surrounding_text = surrounding_text_match.group(0) if surrounding_text_match else \"\"\n",
    "\n",
    "      short_def = re.sub(r\"\\s+\", \" \", surrounding_text).strip()\n",
    "      if len(short_def) > 0:\n",
    "        b_tag_dict.append((f\"{matched_b_tag} {short_def}\", re.sub(r\"[,.]+$\", \"\", matched_b_tag)))\n",
    "\n",
    "    # BUILD NEGATIVE\n",
    "    for match in tqdm(re.finditer(r\"(\\n\\n\\p{Upper}[^<]{10,500})(?=\\n|$|<)\", datastring), disable=(not verbose), desc=\"Negatives\"):\n",
    "      g = match.group(0)\n",
    "      matched_text = re.sub(r\"\\s+\", \" \", g).strip()\n",
    "      b_tag_dict.append((matched_text, \"\"))\n",
    "\n",
    "    return b_tag_dict\n",
    "\n",
    "  definitions_in_test_set = [entry[0] for entry in head_test_set]\n",
    "  b_tag_dict = set()\n",
    "\n",
    "  for edition in ['E1', 'E2']:\n",
    "    dataset = \"\"\n",
    "    for file in datafiles.get(edition):\n",
    "      with open(f\"./dataset/clear_text/NF_{edition}{file}.txt\", \"r\", encoding='utf-8') as fr:\n",
    "        dataset += fr.read()\n",
    "        fr.close()\n",
    "    \n",
    "    edition_b_tag = extract_b_tags(dataset, verbose=True)\n",
    "    b_tag_dict.update(edition_b_tag)\n",
    "    print(f\"{edition} has {len(edition_b_tag):,} entries\")\n",
    "  \n",
    "  final_train_set = []\n",
    "  for entry in tqdm(b_tag_dict, desc=\"Removing Test_Set entries\"):\n",
    "    if entry[0] not in definitions_in_test_set:\n",
    "      final_train_set.append(entry)\n",
    "  print(f\"Found {len(b_tag_dict)-len(final_train_set)} entries already in Test_Set\\nSaving only {len(final_train_set)} to train_set.json\")\n",
    "\n",
    "  with open(\"./dataset/headword/train_set.json\", \"w\") as b_json:\n",
    "    json.dump(final_train_set, b_json, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Load in manually annotated test set. \n",
    "def load_test_set():\n",
    "  with open(\"./dataset/headword/test_set.json\", \"r\", encoding='utf-8') as annotated_test:\n",
    "    test_set = json.load(annotated_test)\n",
    "    annotated_test.close()\n",
    "  return test_set\n",
    "head_test_set = load_test_set()\n",
    "\n",
    "SHOULD_BUILD_HEADWORD_SET = False\n",
    "if SHOULD_BUILD_HEADWORD_SET:\n",
    "  build_json_headword_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the training and test sets using KB-bert ```AutoTokenizer```. The test set is tokenized everytime, but you can choose to turn off the training set tokenization after running it once by toggling off ``` TOKENIZE_TRAIN_SET ```. \n",
    "\n",
    "The tokenized training set is saved to [tokenized_train_set.pth](./dataset/headword/tokenized_train_set.pth), defined by the path ``` TOKNIZED_TRAIN_SET ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.526659Z",
     "iopub.status.busy": "2024-11-16T01:03:04.526523Z",
     "iopub.status.idle": "2024-11-16T01:05:47.982547Z",
     "shell.execute_reply": "2024-11-16T01:05:47.981956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:03<00:00, 1552.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300675, 100]) torch.Size([300675, 100]) torch.Size([5000, 100]) torch.Size([5000, 100])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"KB/bert-base-swedish-cased\")\n",
    "\n",
    "def process_data(sentence, headword):\n",
    "  encoded_sentence = tokenizer(\n",
    "      sentence,\n",
    "      add_special_tokens=True, \n",
    "      padding='max_length',   \n",
    "      max_length=100,        \n",
    "      truncation=True,       \n",
    "      return_tensors='pt'  \n",
    "  )\n",
    "  encoded_headword = tokenizer(\n",
    "      headword,\n",
    "      add_special_tokens=True,\n",
    "      padding='max_length',\n",
    "      max_length=20,           \n",
    "      truncation=True,\n",
    "      return_tensors='pt'\n",
    "  )\n",
    "  return encoded_sentence['input_ids'][0], encoded_headword['input_ids'][0]\n",
    "\n",
    "def extract_features_labels(dataset) -> Tuple[List, List]:\n",
    "  x = []\n",
    "  y = []\n",
    "  for entry in tqdm(dataset):\n",
    "    sentence, headword = process_data(entry[0], entry[1])\n",
    "    x.append(sentence)\n",
    "\n",
    "    min_len = min(len(sentence), len(headword))\n",
    "    headword_mask = np.where((sentence[:min_len] > 4) & (sentence[:min_len] == headword[:min_len]), 1, 0)\n",
    "    headword_mask = np.pad(headword_mask, (0, len(sentence) - min_len), 'constant')\n",
    "    \n",
    "    y.append(torch.tensor(headword_mask))\n",
    "  return torch.stack(x).to(device), torch.stack(y).to(device)\n",
    "\n",
    "def build_headword_dataset(): \n",
    "  with open(\"./dataset/headword/train_set.json\", \"r\", encoding='utf-8') as b_json:\n",
    "    dataset  = json.load(b_json)\n",
    "    b_json.close()\n",
    "  temp_X, temp_y = extract_features_labels(dataset)\n",
    "  torch.save((temp_X,temp_y), TOKNIZED_TRAIN_SET)\n",
    "  return temp_X, temp_y\n",
    "\n",
    "X_test, y_test = extract_features_labels(head_test_set) # <-- Use this to comapre different models. \n",
    "del head_test_set\n",
    "\n",
    "# Either build pytorch dataset out of json, or load in saved pth file.\n",
    "TOKNIZE_TRAIN_SET = False\n",
    "TOKNIZED_TRAIN_SET = './dataset/headword/tokenized_train_set.pth'\n",
    "\n",
    "if TOKNIZE_TRAIN_SET:\n",
    "  X, y = build_headword_dataset()            \n",
    "else:\n",
    "  X, y = torch.load(TOKNIZED_TRAIN_SET, weights_only=True)\n",
    "\n",
    "print(X.shape, y.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example sample in our dataset:\n",
    "  - **Input Sentence**  &nbsp;&emsp;&emsp;&emsp;The extracted feature, which is a random paragraph or a definition of an article. \n",
    "  - **Tokenized Sentence** &emsp;The tokenized input up to a 100 tokens, with ``` CLS = 2 ```, ``` SEP = 3 ``` and ``` PAD = 0 ```\n",
    "  - **Target Mask**   &nbsp;&emsp;&emsp;&emsp;&emsp; The expected label mask, ``` 0 ``` for ``` Out_headword ``` and ``` 1 ``` for ``` In_headword ```\n",
    "  - **Target Headword**   &nbsp;&emsp;&emsp;The decoded headword, constructed by applying the output mask on the tokenized input.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: \n",
      "Pomona. 1. Astron., en af småplaneterna. 2. Rom. myt., hos forntidens romare egentligen fruktträdens gudinna ( namnet härledt af pomum, äpple ). Hon gällde äfven som maka till Vertumnus. I Rom hade hon en särskild präst. Förnämligast dyrkades hon dock på landsbygden. Liksom Vertumnus afbildas P. ofta med trädgårdsknifven och skötet fylldt af\n",
      "\n",
      "Tokenized Sentence: \n",
      "[2, 25576, 3929, 7, 61, 7, 5143, 1066, 7, 19, 59, 4815, 1459, 14642, 183, 7, 93, 7, 2871, 7, 13020, 7, 19, 937, 14362, 18232, 2195, 115, 2559, 34012, 148, 6728, 1452, 177, 4586, 382, 681, 49795, 4815, 1065, 42257, 49801, 19, 35708, 171, 7, 807, 5829, 400, 49808, 170, 67, 5968, 76, 6244, 16583, 1146, 164, 7, 135, 2871, 365, 295, 59, 4850, 8161, 7, 43737, 180, 26119, 35005, 439, 295, 909, 68, 13034, 7, 10141, 6244, 16583, 1146, 164, 4815, 14719, 49796, 133, 7, 1468, 66, 26072, 2061, 775, 170, 36, 5528, 11, 13215, 49795, 4815, 3]\n",
      "\n",
      "Target Mask: \n",
      "[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Target Headword: \n",
      "Pomona\n"
     ]
    }
   ],
   "source": [
    "example_index = 0\n",
    "input = X[example_index]\n",
    "mask = y[example_index]\n",
    "headword = X[example_index][torch.flatten(torch.nonzero(y[example_index]))]\n",
    "print(f\"Input Sentence: \\n{tokenizer.decode(input, skip_special_tokens=True)}\\n\")\n",
    "print(f\"Tokenized Sentence: \\n{input.tolist()}\\n\")\n",
    "print(f\"Target Mask: \\n{mask.tolist()}\\n\")\n",
    "print(f\"Target Headword: \\n{tokenizer.decode(headword, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training set into training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:47.986360Z",
     "iopub.status.busy": "2024-11-16T01:05:47.986218Z",
     "iopub.status.idle": "2024-11-16T01:05:48.146526Z",
     "shell.execute_reply": "2024-11-16T01:05:48.145965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 50325\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20) # <-- Use to train our model or fine-tune a model.\n",
    "print(\"Vocab size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train model\n",
    "``` HeadwordExtractor ``` class containing the ``` EncoderLSTM ``` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:53.055633Z",
     "iopub.status.busy": "2024-11-16T01:05:53.055402Z",
     "iopub.status.idle": "2024-11-16T01:05:53.058296Z",
     "shell.execute_reply": "2024-11-16T01:05:53.057940Z"
    }
   },
   "outputs": [],
   "source": [
    "class HeadwordExtractor():\n",
    "  def __init__(self, saved_model):\n",
    "    self.embedding_dim = 128\n",
    "    self.hidden_dim = 128\n",
    "    self.batch_size = 32\n",
    "    self.num_epochs = 3\n",
    "    self.learning_rate = 0.001\n",
    "    self.saved_model = saved_model\n",
    "    \n",
    "    self.train_loader = DataLoader(TensorDataset(X_train.long(), y_train.long()), batch_size=self.batch_size, shuffle=True)\n",
    "    self.val_loader = DataLoader(TensorDataset(X_val.long(), y_val.long()), batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    self.model = self.EncoderLSTM(tokenizer.vocab_size, self.embedding_dim, self.hidden_dim, nbr_classes=2, num_layers=1,bidi_lstm=True).to(device)\n",
    "\n",
    "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "    print(self.model)\n",
    "\n",
    "  class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, nbr_classes, num_layers=1, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=tokenizer.pad_token_id)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=bidi_lstm, dropout=(0.5 if num_layers > 1 else 0))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(hidden_dim, nbr_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(2*hidden_dim, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        encoder_out, _ = self.encoder(embeds)\n",
    "        encoder_out = nn.functional.relu(encoder_out)\n",
    "        drop_out = self.drop(encoder_out)\n",
    "        logits = self.fc(drop_out)\n",
    "        return logits\n",
    "\n",
    "  def train_extractor(self):\n",
    "    history=[]\n",
    "    for epoch in range(self.num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{self.num_epochs}:\")\n",
    "      \n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "        temp = 0\n",
    "        for input_batch, target_batch in tqdm(self.train_loader, desc = \"Training\"):\n",
    "            outputs = self.model(input_batch)\n",
    "\n",
    "            loss = self.criterion(outputs.view(-1,outputs.shape[-1]), target_batch.view(-1))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_accuracy += (torch.sum(outputs.view(-1,outputs.shape[-1]).argmax(dim=1) == target_batch.view(-1))/target_batch.view(-1).shape[0]).item()\n",
    "        avg_train_loss = train_loss / len(self.train_loader)\n",
    "        avg_train_acc = train_accuracy / len(self.train_loader)\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_acc:.4f}\")\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_accuracy = 0\n",
    "            for input_batch, target_batch in tqdm(self.val_loader, desc = \"Validation\"):\n",
    "              outputs = self.model(input_batch)\n",
    "\n",
    "              loss = self.criterion(outputs.view(-1,outputs.shape[-1]), target_batch.view(-1))\n",
    "              val_loss += loss.item()\n",
    "              val_accuracy += (torch.sum(outputs.view(-1,outputs.shape[-1]).argmax(dim=1) == target_batch.view(-1))/target_batch.view(-1).shape[0]).item()\n",
    "        avg_val_loss = val_loss/len(self.val_loader)\n",
    "        avg_val_acc = val_accuracy / len(self.val_loader)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_acc:.4f}\\n\")\n",
    "\n",
    "        history.append((avg_train_loss, avg_train_acc, avg_val_loss, avg_val_acc))\n",
    "    self.__plot_metrics(history)\n",
    "\n",
    "  def __plot_metrics(self, history):\n",
    "    train_loss, train_acc, val_loss, val_acc = tuple(zip(*history))\n",
    "    epochs = range(1, len(history) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_acc, marker='o', linestyle='-', label='Train Accuracy')\n",
    "    plt.plot(epochs, val_acc, marker='o', linestyle='-', label='Validation Accuracy')\n",
    "    plt.title('Validation vs Train Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, train_loss, marker='o', linestyle='-', label='Train Loss')\n",
    "    plt.plot(epochs, val_loss, marker='o', linestyle='-', label='Validation Loss')\n",
    "    plt.title('Validation vs Train Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "  def predict(self, encoded_input):\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "      output_mask = self.model(encoded_input).argmax(dim=-1).cpu()\n",
    "      \n",
    "    for entry_index, token_index in enumerate(output_mask.argmax(1)):\n",
    "      while_index = token_index\n",
    "      while output_mask[entry_index, while_index] == 1 and while_index > 0 and tokenizer.decode(encoded_input[entry_index, while_index]).startswith(\"##\"):\n",
    "        output_mask[entry_index, while_index-1] = 1\n",
    "        while_index-=1\n",
    "\n",
    "    return output_mask\n",
    "  \n",
    "  def load_model(self):\n",
    "     self.model.load_state_dict(torch.load(self.saved_model, weights_only=True))\n",
    "     self.model.eval()\n",
    "  \n",
    "  def save_model(self):\n",
    "     torch.save(self.model.state_dict(), self.saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and save model into [headword_extractor.pth](./models/headword/headword_extractor.pth) , or load model from saved file with path ``` SAVED_MODEL ```. \n",
    "\n",
    "Toggle boolean ``` TRAIN_NEW_MODEL ``` to switch between methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderLSTM(\n",
      "  (embeddings): Embedding(50325, 128, padding_idx=0)\n",
      "  (encoder): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "SAVED_MODEL = \"./models/headword/headword_extractor.pth\"\n",
    "\n",
    "extractor = HeadwordExtractor(saved_model=SAVED_MODEL)\n",
    "\n",
    "TRAIN_NEW_MODEL = False\n",
    "if TRAIN_NEW_MODEL:\n",
    "  extractor.train_extractor()\n",
    "  extractor.save_model()\n",
    "else:\n",
    "  extractor.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate **HeadwordExtractor**\n",
    "Split between ``` headword ``` samples and ``` none_headowrd ``` samples in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4354, 646)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_positives = (y_test.sum(dim=1) > 0).sum().item()\n",
    "test_negatives = (y_test.sum(dim=1) == 0).sum().item()\n",
    "test_positives,test_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set and produce, ``` accuracy_score ```, ``` classification_report ``` and ``` confusion_matrix ``` from **Scikit-learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.77%\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    486447\n",
      "           1       0.98      0.93      0.96     13553\n",
      "\n",
      "    accuracy                           1.00    500000\n",
      "   macro avg       0.99      0.97      0.98    500000\n",
      "weighted avg       1.00      1.00      1.00    500000\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_predictions = extractor.predict(X_test)\n",
    "flattend_y_test_predictions = y_test_predictions.view(-1)\n",
    "flattend_y_test = y_test.view(-1).cpu()\n",
    "\n",
    "print(f\"Test Accuracy: {(accuracy_score(flattend_y_test, flattend_y_test_predictions)*100):.2f}%\")\n",
    "print(f\"Classification Report: \\n{classification_report(flattend_y_test, flattend_y_test_predictions)}\")\n",
    "cm = confusion_matrix(flattend_y_test, flattend_y_test_predictions, normalize='pred')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[0,1])\n",
    "cmd.plot()\n",
    "print(\"Confusion Matrix:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model in inference mode, change ``` input_sentence ``` to a *definition-like* piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T04:02:51.484972Z",
     "iopub.status.busy": "2024-11-16T04:02:51.484820Z",
     "iopub.status.idle": "2024-11-16T04:02:51.586294Z",
     "shell.execute_reply": "2024-11-16T04:02:51.585934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted headword: Gustav Vasa\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"Gustav Vasa, ursprungligen Gustav Eriksson,[2] enligt flera källor född 12 maj 1496, död 29 september 1560 på Tre Kronor i Stockholm.[3] var kung av Sverige 1523–1560 och riksföreståndare 1521–1523, under det pågående befrielsekriget. Hans makttillträde, inlett som ett uppror mot unionskungen Kristian II efter Stockholms blodbad, innebar slutet för Kalmarunionen. Gustav tillhörde Vasaätten, som genom\"\n",
    "encoded_input = tokenizer(input_sentence, return_tensors=\"pt\", padding = \"max_length\", max_length = 100, truncation = True)['input_ids'].to(device)\n",
    "\n",
    "output_mask = extractor.predict(encoded_input).view(-1)\n",
    "headword = encoded_input.cpu().view(-1)[torch.flatten(torch.nonzero(output_mask))]\n",
    "decoded_headword = tokenizer.decode(headword, skip_special_tokens=True)\n",
    "print(\"Predicted headword:\", decoded_headword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Headwords from editions\n",
    "\n",
    "Tokenize all the editions using their txt formats and save them into a single file [tokenized_editions.pth](./dataset/clear_text/tokenized_editions.pth).\n",
    "\n",
    "You can load in the tokenized file by toggling off the ``` SHOULD_TOKENIZE_EDITIONS ``` if you have tokenized at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_editions():\n",
    "  tokenized_editions = []\n",
    "  for edition in datafiles.keys():\n",
    "    edition_data = \"\"\n",
    "    for file in datafiles.get(edition):\n",
    "      with open(f\"./dataset/clear_text/NF_{edition}{file}.txt\", \"r\", encoding='utf-8') as fr:\n",
    "        edition_data += fr.read()\n",
    "        fr.close()\n",
    "    edition_data = re.sub(r\"<b>|</b>\", \"\", edition_data)\n",
    "    \n",
    "    splitted_paragraphs = re.split(r\"\\n\\n\", edition_data)\n",
    "    filterd_paragraphs = filter(lambda p: len(p) >= 10, splitted_paragraphs)\n",
    "    truncated_paragraphs = map(lambda p: p[:500] if len(p) > 500 else p, filterd_paragraphs)\n",
    "    \n",
    "    paragraphs = torch.stack(\n",
    "      [tokenizer(\n",
    "          p,\n",
    "          add_special_tokens=True, \n",
    "          padding='max_length',   \n",
    "          max_length=100,        \n",
    "          truncation=True,       \n",
    "          return_tensors='pt'  \n",
    "        )['input_ids'][0] \n",
    "        for p in tqdm(list(truncated_paragraphs))\n",
    "      ]).to(device)\n",
    "    tokenized_editions.append(paragraphs)\n",
    "  torch.save(tokenized_editions, './dataset/clear_text/tokenized_editions.pth')\n",
    "  return tokenized_editions\n",
    "\n",
    "SHOULD_TOKENIZE_EDITIONS = False\n",
    "if SHOULD_TOKENIZE_EDITIONS:\n",
    "  editions = tokenize_editions()\n",
    "else:\n",
    "  editions = torch.load('./dataset/clear_text/tokenized_editions.pth', weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model *``` extractor ```* defined above, to predict and decode all the toknized editions. Discarding any entries predicted as a ``` none_headword ``` and saving the headword entires into [extracted_entries.json](./dataset/extracted_entries.json).\n",
    "\n",
    "This task can take quite a long time, therefore you can yet again toggle off ``` PREDICT_EDITIONS ``` to only load in the extracted entries from the saved json file with the path ``` PREDICTED_EDITIONS ```.\n",
    "\n",
    "The output given is the number of headwords per edition followed by the total sum:\n",
    "\n",
    "``` (nbr_headwords_E1, nbr_headwords_E2, nbr_headwords_E3, nbr_headwords_E4, total_headwords) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117473, 185063, 26464, 89221, 418221)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_editions():\n",
    "  db = {}\n",
    "  for ei, edition in enumerate(editions):\n",
    "    # Predict editions by batches:\n",
    "    edition_loader = DataLoader(edition, batch_size=19000, shuffle=False)\n",
    "    edition_predictions = torch.empty((0,100)).to(device)\n",
    "    for batch in tqdm(edition_loader, desc=f\"Predicting Edtion E{ei+1}\"):\n",
    "      batch_prediction = extractor.predict(batch).to(device)\n",
    "      edition_predictions = torch.cat((edition_predictions, batch_prediction))\n",
    "\n",
    "    # Filter away non-headword predictions:\n",
    "    predicted_input = edition[torch.unique(torch.nonzero(edition_predictions)[:, 0])]\n",
    "    predicted_masks = edition_predictions[torch.unique(torch.nonzero(edition_predictions)[:, 0])]\n",
    "    predicted_entries = []\n",
    "    entry_cnt = 0\n",
    "    for input, mask in tqdm(list(zip(predicted_input,predicted_masks)), desc=f\"Decoding   Edtion E{ei+1}\"):\n",
    "      decoded_headword = tokenizer.decode(input[mask.nonzero().flatten()], skip_special_tokens=True)\n",
    "      decoded_headword = re.sub(r\",\", \"\", decoded_headword)\n",
    "      if decoded_headword != \"\":\n",
    "        decoded_input = tokenizer.decode(input, skip_special_tokens=True)\n",
    "\n",
    "        if not re.search(r\"^Bild [\\diI]+\", decoded_input):\n",
    "          entry_cnt+=1\n",
    "          predicted_entries.append({\"entry_id\": f\"E{ei+1}_{entry_cnt}\", \"headword\": decoded_headword, \"definition\": decoded_input})\n",
    "          \n",
    "    db[f\"E{ei+1}\"] = predicted_entries\n",
    "\n",
    "  with open(PREDICTED_EDITIONS, \"w\") as entry_json:\n",
    "    json.dump(db, entry_json, indent=2, ensure_ascii=False)\n",
    "    entry_json.close()\n",
    "\n",
    "def load_in_db():\n",
    "  try:\n",
    "    with open(PREDICTED_EDITIONS, \"r\", encoding='utf-8') as entry_json_r:\n",
    "      db = json.load(entry_json_r)\n",
    "      entry_json_r.close()\n",
    "  except:\n",
    "    db = {}\n",
    "  return db\n",
    "\n",
    "PREDICT_EDITIONS = False\n",
    "PREDICTED_EDITIONS = \"./dataset/extracted_entries.json\"\n",
    "if PREDICT_EDITIONS:\n",
    "  predict_editions()\n",
    "\n",
    "db = load_in_db()\n",
    "len(db['E1']), len(db['E2']), len(db['E3']), len(db['E4']), len(db['E1']) + len(db['E2']) + len(db['E3']) + len(db['E4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| nbr unfronzen | Test Acc    | Macro Avg   |\n",
    "| --------      | -------     | -------     |\n",
    "|       0       | 0.6711      | 0.6779      |\n",
    "|       2       | 0.8889      | 0.8943      |\n",
    "|       4       | 0.9000      | 0.9028      |\n",
    "|       6       | 0.9044      | 0.9078      |\n",
    "|       8       | 0.9089      | 0.9106      |\n",
    "|      10       | **0.9156**  | **0.9175**  |\n",
    "|      12       | 0.9089      | 0.9095      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 62159, 2: 27760, 1: 27554})\n",
      "Counter({0: 107838, 1: 40423, 2: 36802})\n",
      "Counter({0: 14487, 2: 7127, 1: 4850})\n",
      "Counter({0: 54211, 1: 18794, 2: 16216})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "with open(\"./dataset/predicted_ner_entries.json\", \"r\", encoding='utf-8') as ner_in:\n",
    "  ner_db = json.load(ner_in)\n",
    "  ner_in.close()\n",
    "\n",
    "for e in datafiles.keys():\n",
    "  print(Counter([entry['type'] for entry in ner_db[e]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 batch NER\n",
    "\n",
    "E1 ({0: 59789, 1: 29360, 2: 28324})\n",
    "\n",
    "E2 ({0: 105073, 1: 43010, 2: 36980})\n",
    "\n",
    "E3 ({0: 14166, 2: 7076, 1: 5222})\n",
    "\n",
    "E4 ({0: 52984, 1: 19639, 2: 16598})\n",
    "\n",
    "### Ancient NER \n",
    "'E1': {0: 65622, 1: 16166, 2: 35841}\n",
    "\n",
    "'E2': {0: 109085, 1: 22687, 2: 46677}\n",
    "\n",
    "'E3': {0: 13980, 2: 7872, 1: 3153}\n",
    "\n",
    "'E4': {0: 52048, 2: 19948, 1: 12171}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
