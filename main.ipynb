{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "Imports and define names of datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:02:45.075847Z",
     "iopub.status.busy": "2024-11-16T01:02:45.075725Z",
     "iopub.status.idle": "2024-11-16T01:03:04.070511Z",
     "shell.execute_reply": "2024-11-16T01:03:04.069918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  \n",
    "from typing import List,Tuple\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "datafiles= {\n",
    "  \"E1\" : [''],\n",
    "  \"E2\" : ['a', 'b'],\n",
    "  \"E3\" : [''],\n",
    "  \"E4\" : ['']\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that extracts headwords out of \\<b\\> tags to build a headword dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.072450Z",
     "iopub.status.busy": "2024-11-16T01:03:04.072169Z",
     "iopub.status.idle": "2024-11-16T01:03:04.076453Z",
     "shell.execute_reply": "2024-11-16T01:03:04.076091Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_b_tag_dataset(datastring, next_chars = 500, verbose=False):\n",
    "  b_tag_dict = []\n",
    "\n",
    "  # BUILD POSITIVE \n",
    "  for match in tqdm(re.finditer(r\"((?<=<b>).+<\\/b>)(.*(?<=<b>).+<\\/b>)*\", datastring), disable=(not verbose)):\n",
    "    g1 = match.group(0)\n",
    "    matched_b_tag = re.sub(r\"</b>.*<b>|</b>\",\" \",g1).strip()\n",
    "    matched_b_tag = re.sub(r\"[,.]+$\", \"\", matched_b_tag)\n",
    "    end_of_b_tag = match.end()  \n",
    "    \n",
    "    surrounding_text_match = re.search(r\"([^<]{1,\"+str(next_chars)+r\"})(?=<|$)\", datastring[end_of_b_tag:end_of_b_tag+next_chars])\n",
    "    surrounding_text = surrounding_text_match.group(0) if surrounding_text_match else \"\"\n",
    "\n",
    "    short_def = re.sub(r\"\\s+\", \" \", surrounding_text).strip()\n",
    "    if len(short_def) > 0:\n",
    "      b_tag_dict.append([f\"{matched_b_tag} {short_def}\", matched_b_tag])\n",
    "\n",
    "  # BUILD NEGATIVE\n",
    "  for match in tqdm(re.finditer(r\"(\\n\\n\\p{Upper}[^<]{10,500})(?=\\n|$|<)\", datastring), disable=(not verbose)):\n",
    "    g = match.group(0)\n",
    "    matched_text = re.sub(r\"\\s+\", \" \", g).strip()\n",
    "    b_tag_dict.append([matched_text, \"\"])\n",
    "\n",
    "  return b_tag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the headword datasets for the first and second editions (E1 \\& E2) where for each entry there is:\n",
    "  - Feature: A paragraph or piece of text that starts with a headword, followed by up to <i>next_chars</i> number of characters, default is 500.\n",
    "  - label: The headword at the beginning of the corresponding feature, empty string if feature wasn't a <i>\"headword\"</i> paragraph.\n",
    "\n",
    "Save results to json files:\n",
    "```json\n",
    "  [\"Lund, uppstad i Malmöhus län...beskaffenhet. I all\", \"Lund,\"]\n",
    "  [\"betjenade sig af rapporter från...till privatlifvet\", \"\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.077819Z",
     "iopub.status.busy": "2024-11-16T01:03:04.077689Z",
     "iopub.status.idle": "2024-11-16T01:03:04.079708Z",
     "shell.execute_reply": "2024-11-16T01:03:04.079366Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_json_headword_set():\n",
    "  for edition in ['E1', 'E2']:\n",
    "\n",
    "    dataset = \"\"\n",
    "    for file in datafiles.get(edition):\n",
    "      with open(f\"./dataset/NF_{edition}{file}.txt\", \"r\", encoding='utf-8') as fr:\n",
    "        dataset += fr.read()\n",
    "        fr.close()\n",
    "        \n",
    "    b_tag_dict = build_b_tag_dataset(dataset, verbose=True)\n",
    "    print(f\"{edition} has {len(b_tag_dict):,} entries\")\n",
    "\n",
    "    with open(f\"./dataset/NF_{edition}_B.json\", \"w\") as b_json:\n",
    "      json.dump(b_tag_dict, b_json, indent=2, ensure_ascii=False)\n",
    "  del edition, dataset, file, fr, b_tag_dict, b_json\n",
    "\n",
    "SHOULD_BUILD_B_TAG = False\n",
    "if SHOULD_BUILD_B_TAG:\n",
    "  build_json_headword_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:03:04.526659Z",
     "iopub.status.busy": "2024-11-16T01:03:04.526523Z",
     "iopub.status.idle": "2024-11-16T01:05:47.982547Z",
     "shell.execute_reply": "2024-11-16T01:05:47.981956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:03<00:00, 1621.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([303448, 100]), torch.Size([303448, 100]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"KB/bert-base-swedish-cased\")\n",
    "\n",
    "def process_data(sentence, headword):\n",
    "    encoded_sentence = tokenizer(\n",
    "        sentence,\n",
    "        add_special_tokens=True, \n",
    "        padding='max_length',   \n",
    "        max_length=100,        \n",
    "        truncation=True,       \n",
    "        return_tensors='pt'  \n",
    "    )\n",
    "    encoded_headword = tokenizer(\n",
    "        headword,\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        max_length=20,           \n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoded_sentence['input_ids'][0], encoded_headword['input_ids'][0]\n",
    "\n",
    "def extract_features_labels(dataset) -> Tuple[List, List]:\n",
    "    x = []\n",
    "    y = []\n",
    "    for entry in tqdm(dataset):\n",
    "      sentence, headword = process_data(entry[0], entry[1])\n",
    "      x.append(sentence)\n",
    "\n",
    "      min_len = min(len(sentence), len(headword))\n",
    "      headword_mask = np.where((sentence[:min_len] > 4) & (sentence[:min_len] == headword[:min_len]), 1, 0)\n",
    "      headword_mask = np.pad(headword_mask, (0, len(sentence) - min_len), 'constant')\n",
    "      \n",
    "      y.append(torch.tensor(headword_mask))\n",
    "    return torch.stack(x).to(device), torch.stack(y).to(device)\n",
    "\n",
    "def build_headword_dataset():\n",
    "  def load_headword_json():\n",
    "    out = []\n",
    "    for edition in ['E1', 'E2']:\n",
    "        with open(f\"./dataset/NF_{edition}_B.json\", \"r\", encoding='utf-8') as b_json:\n",
    "          out += json.load(b_json)\n",
    "          b_json.close()\n",
    "    return out\n",
    "  dataset = load_headword_json()\n",
    "  random.seed(123)\n",
    "  random.shuffle(dataset)\n",
    "  dataset = dataset[5000:]\n",
    "  temp_X, temp_y = extract_features_labels(dataset)\n",
    "  torch.save((temp_X,temp_y),'./dataset/headword_dataset.pth')\n",
    "  return temp_X, temp_y\n",
    "\n",
    "# Load in manually annotated test set. \n",
    "with open(\"./dataset/NF_test_set_12_annotated.json\", \"r\", encoding='utf-8') as annotated_test:\n",
    "  test_set = json.load(annotated_test)\n",
    "  annotated_test.close()\n",
    "X_test, y_test = extract_features_labels(test_set) # <-- Use this to comapre different models. \n",
    "\n",
    "# Either build pytorch dataset out of json, or load in saved pth file.\n",
    "BUILD_HEADWORD = False\n",
    "if BUILD_HEADWORD:\n",
    "  X, y = build_headword_dataset()            \n",
    "else:\n",
    "  X, y = torch.load('./dataset/headword_dataset.pth', weights_only=True)\n",
    "X.shape, y.shape # <-- Use this to train our model or fine-tune a model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: \n",
      "Bondesen Ingvor, dansk författare, f. 1844, var 186485 skollärare på Fyn, blef därefter anställd i Köpenhamns skolväsen och 1892 skolinspektör vid en af skolorna därstädes. Han började 1877 under märket Henning Fox att skrifva historiska romaner från den äldre medeltiden, Styrismanden og hans brud ( 1877 ) och Kongsbrydens fostersön ( 1878 ). Senare följde berättelser med ämnen från adelsväldets tid, Rettergang og skriftegang (\n",
      "\n",
      "Tokenized Sentence: \n",
      "[2, 17431, 436, 1613, 8143, 19, 5908, 4567, 19, 13, 7, 21978, 49841, 19, 96, 42581, 5727, 16964, 4759, 68, 48349, 19, 21829, 49808, 3386, 7410, 31, 32754, 1005, 28343, 36, 35907, 1005, 17969, 252, 59, 4815, 13349, 256, 23055, 7, 371, 1649, 42456, 244, 19997, 15860, 13469, 48, 1147, 49808, 384, 8521, 15797, 146, 97, 2332, 21045, 19, 15307, 2894, 963, 5196, 699, 14503, 177, 42456, 171, 36, 7954, 9213, 389, 148, 11989, 21345, 177, 40999, 171, 7, 9475, 5622, 12631, 66, 7114, 146, 23410, 746, 1730, 353, 290, 19, 17187, 95, 19612, 5196, 4653, 24640, 49802, 177, 3]\n",
      "\n",
      "Target Mask: \n",
      "[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Target Headword: \n",
      "Bondesen\n"
     ]
    }
   ],
   "source": [
    "example_index = 1\n",
    "input = X[example_index]\n",
    "mask = y[example_index]\n",
    "headword = X[example_index][torch.flatten(torch.nonzero(y[example_index]))]\n",
    "print(f\"Input Sentence: \\n{tokenizer.decode(input, skip_special_tokens=True)}\\n\")\n",
    "print(f\"Tokenized Sentence: \\n{input.tolist()}\\n\")\n",
    "print(f\"Target Mask: \\n{mask.tolist()}\\n\")\n",
    "print(f\"Target Headword: \\n{tokenizer.decode(headword, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:47.986360Z",
     "iopub.status.busy": "2024-11-16T01:05:47.986218Z",
     "iopub.status.idle": "2024-11-16T01:05:48.146526Z",
     "shell.execute_reply": "2024-11-16T01:05:48.145965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 50325\n",
      "Max input ID: 49968\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20) # <-- Use to train our model or fine-tune a model.\n",
    "print(\"Vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Max input ID:\", torch.max(X_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:05:53.055633Z",
     "iopub.status.busy": "2024-11-16T01:05:53.055402Z",
     "iopub.status.idle": "2024-11-16T01:05:53.058296Z",
     "shell.execute_reply": "2024-11-16T01:05:53.057940Z"
    }
   },
   "outputs": [],
   "source": [
    "class HeadwordExtractor():\n",
    "  def __init__(self, saved_model):\n",
    "    self.embedding_dim = 128\n",
    "    self.hidden_dim = 128\n",
    "    self.batch_size = 32\n",
    "    self.num_epochs = 5\n",
    "    self.learning_rate = 0.001\n",
    "    self.saved_model = saved_model\n",
    "    \n",
    "    self.train_loader = DataLoader(TensorDataset(X_train.long(), y_train.long()), batch_size=self.batch_size, shuffle=True)\n",
    "    self.val_loader = DataLoader(TensorDataset(X_val.long(), y_val.long()), batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    self.model = self.EncoderLSTM(tokenizer.vocab_size, self.embedding_dim, self.hidden_dim, nbr_classes=2, num_layers=1,bidi_lstm=True).to(device)\n",
    "\n",
    "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "    print(self.model)\n",
    "\n",
    "  class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, nbr_classes, num_layers=1, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=tokenizer.pad_token_id)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=bidi_lstm, dropout=(0.5 if num_layers > 1 else 0))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(hidden_dim, nbr_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(2*hidden_dim, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        encoder_out, _ = self.encoder(embeds)\n",
    "        encoder_out = nn.functional.relu(encoder_out)\n",
    "        drop_out = self.drop(encoder_out)\n",
    "        logits = self.fc(drop_out)\n",
    "        return logits\n",
    "\n",
    "  def train_extractor(self):\n",
    "    history=[]\n",
    "    for epoch in range(self.num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{self.num_epochs}:\")\n",
    "      \n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "        temp = 0\n",
    "        for input_batch, target_batch in tqdm(self.train_loader, desc = \"Training\"):\n",
    "            outputs = self.model(input_batch)\n",
    "\n",
    "            loss = self.criterion(outputs.view(-1,outputs.shape[-1]), target_batch.view(-1))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_accuracy += (torch.sum(outputs.view(-1,outputs.shape[-1]).argmax(dim=1) == target_batch.view(-1))/target_batch.view(-1).shape[0]).item()\n",
    "        avg_train_loss = train_loss / len(self.train_loader)\n",
    "        avg_train_acc = train_accuracy / len(self.train_loader)\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_acc:.4f}\")\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_accuracy = 0\n",
    "            for input_batch, target_batch in tqdm(self.val_loader, desc = \"Validation\"):\n",
    "              outputs = self.model(input_batch)\n",
    "\n",
    "              loss = self.criterion(outputs.view(-1,outputs.shape[-1]), target_batch.view(-1))\n",
    "              val_loss += loss.item()\n",
    "              val_accuracy += (torch.sum(outputs.view(-1,outputs.shape[-1]).argmax(dim=1) == target_batch.view(-1))/target_batch.view(-1).shape[0]).item()\n",
    "        avg_val_loss = val_loss/len(self.val_loader)\n",
    "        avg_val_acc = val_accuracy / len(self.val_loader)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_acc:.4f}\\n\")\n",
    "\n",
    "        history.append((avg_train_loss, avg_train_acc, avg_val_loss, avg_val_acc))\n",
    "    self.__plot_metrics(history)\n",
    "\n",
    "  def __plot_metrics(self, history):\n",
    "    train_loss, train_acc, val_loss, val_acc = tuple(zip(*history))\n",
    "    epochs = range(1, len(history) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_acc, marker='o', linestyle='-', label='Train Accuracy')\n",
    "    plt.plot(epochs, val_acc, marker='o', linestyle='-', label='Validation Accuracy')\n",
    "    plt.title('Validation vs Train Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, train_loss, marker='o', linestyle='-', label='Train Loss')\n",
    "    plt.plot(epochs, val_loss, marker='o', linestyle='-', label='Validation Loss')\n",
    "    plt.title('Validation vs Train Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "  def predict(self, encoded_input):\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "      output_mask = self.model(encoded_input).argmax(dim=-1).cpu()\n",
    "      \n",
    "    for entry_index, token_index in enumerate(output_mask.argmax(1)):\n",
    "      while_index = token_index\n",
    "      while output_mask[entry_index, while_index] == 1 and while_index > 0 and tokenizer.decode(encoded_input[entry_index, while_index]).startswith(\"##\"):\n",
    "        output_mask[entry_index, while_index-1] = 1\n",
    "        while_index-=1\n",
    "\n",
    "    return output_mask\n",
    "  \n",
    "  def load_model(self):\n",
    "     self.model.load_state_dict(torch.load(self.saved_model, weights_only=True))\n",
    "     self.model.eval()\n",
    "  \n",
    "  def save_model(self):\n",
    "     torch.save(self.model.state_dict(), self.saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HeadwordExtractor():\n",
    "#     def __init__(self, saved_model):\n",
    "#         self.embedding_dim = 128\n",
    "#         self.hidden_dim = 128\n",
    "#         self.batch_size = 32\n",
    "#         self.num_epochs = 2\n",
    "#         self.learning_rate = 0.001\n",
    "#         self.saved_model = saved_model\n",
    "        \n",
    "#         self.train_loader = DataLoader(TensorDataset(X_train.long(), y_train.long()), batch_size=self.batch_size, shuffle=True)\n",
    "#         self.val_loader = DataLoader(TensorDataset(X_val.long(), y_val.long()), batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "#         self.model = self.HeadwordClassifierBERT().to(device)\n",
    "\n",
    "#         self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "#         print(self.model)\n",
    "\n",
    "#     class HeadwordClassifierBERT(nn.Module):\n",
    "#         def __init__(self):\n",
    "#             super().__init__()\n",
    "#             self.bert = BertModel.from_pretrained(\"KB/bert-base-swedish-cased-ner\")\n",
    "#             self.bert.resize_token_embeddings(len(tokenizer))\n",
    "#             for param in self.bert.parameters():\n",
    "#                 param.requires_grad = False\n",
    "#             # for param in self.bert.encoder.layer[-1].parameters():\n",
    "#             #     param.requires_grad = True\n",
    "#             self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "#         def forward(self, input_ids, attention_mask):\n",
    "#             outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             sequence_output = outputs.last_hidden_state  # Use last_hidden_state for token-level classification\n",
    "#             #sequence_output = self.dropout(sequence_output)\n",
    "#             logits = self.classifier(sequence_output)\n",
    "#             return logits\n",
    "        \n",
    "#     def train_extractor(self):\n",
    "#         history = []\n",
    "#         for epoch in range(self.num_epochs):\n",
    "#             print(f\"Epoch {epoch+1}/{self.num_epochs}:\")\n",
    "\n",
    "#             self.model.train()\n",
    "#             train_loss = 0\n",
    "#             train_accuracy = 0\n",
    "#             for input_batch, target_batch in tqdm(self.train_loader, desc=\"Training\"):\n",
    "#                 input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "#                 # Verify label indices\n",
    "#                 attention_mask = (input_batch != tokenizer.pad_token_id).to(device)\n",
    "\n",
    "#                 outputs = self.model(input_batch, attention_mask)\n",
    "#                 loss = self.criterion(outputs.view(-1, outputs.shape[-1]), target_batch.view(-1))\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 self.optimizer.step()\n",
    "\n",
    "#                 train_loss += loss.item()\n",
    "#                 train_accuracy += (torch.sum(outputs.view(-1, outputs.shape[-1]).argmax(dim=1) == target_batch.view(-1)) / target_batch.view(-1).shape[0]).item()\n",
    "            \n",
    "#             avg_train_loss = train_loss / len(self.train_loader)\n",
    "#             avg_train_acc = train_accuracy / len(self.train_loader)\n",
    "#             print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_acc:.4f}\")\n",
    "\n",
    "#             self.model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 val_loss = 0\n",
    "#                 val_accuracy = 0\n",
    "#                 for input_batch, target_batch in tqdm(self.val_loader, desc=\"Validation\"):\n",
    "#                     input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "#                     attention_mask = (input_batch != tokenizer.pad_token_id).to(device)\n",
    "#                     outputs = self.model(input_batch, attention_mask)\n",
    "#                     loss = self.criterion(outputs.view(-1, outputs.shape[-1]), target_batch.view(-1))\n",
    "#                     val_loss += loss.item()\n",
    "#                     val_accuracy += (torch.sum(outputs.view(-1, outputs.shape[-1]).argmax(dim=1) == target_batch.view(-1)) / target_batch.view(-1).shape[0]).item()\n",
    "                \n",
    "#                 avg_val_loss = val_loss / len(self.val_loader)\n",
    "#                 avg_val_acc = val_accuracy / len(self.val_loader)\n",
    "#                 print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_acc:.4f}\\n\")\n",
    "#                 history.append((avg_train_loss, avg_train_acc, avg_val_loss, avg_val_acc))\n",
    "\n",
    "#             if epoch == 1:\n",
    "#                 print(\"Unfreezing BERT layers...\")\n",
    "#                 for param in self.model.bert.parameters():\n",
    "#                     param.requires_grad = True\n",
    "        \n",
    "#         self.__plot_metrics(history)\n",
    "\n",
    "#     def __plot_metrics(self, history):\n",
    "#         train_loss, train_acc, val_loss, val_acc = tuple(zip(*history))\n",
    "#         epochs = range(1, len(history) + 1)\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.plot(epochs, train_acc, marker='o', linestyle='-', label='Train Accuracy')\n",
    "#         plt.plot(epochs, val_acc, marker='o', linestyle='-', label='Validation Accuracy')\n",
    "#         plt.title('Validation vs Train Accuracy')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.plot(epochs, train_loss, marker='o', linestyle='-', label='Train Loss')\n",
    "#         plt.plot(epochs, val_loss, marker='o', linestyle='-', label='Validation Loss')\n",
    "#         plt.title('Validation vs Train Loss')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     def predict(self, encoded_input):\n",
    "#         self.model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             attention_mask = (encoded_input != tokenizer.pad_token_id).to(device)\n",
    "#             output_mask = self.model(encoded_input, attention_mask).argmax(dim=-1).view(-1).cpu()\n",
    "#         return output_mask\n",
    "    \n",
    "#     def load_model(self):\n",
    "#         self.model.load_state_dict(torch.load(self.saved_model, weights_only=True,map_location=device))\n",
    "#         self.model.eval()\n",
    "    \n",
    "#     def save_model(self):\n",
    "#         torch.save(self.model.state_dict(), self.saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train or load model from saved file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderLSTM(\n",
      "  (embeddings): Embedding(50325, 128, padding_idx=0)\n",
      "  (encoder): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "SAVED_MODEL = \"headword_extractor.pth\"\n",
    "\n",
    "\n",
    "extractor = HeadwordExtractor(saved_model=SAVED_MODEL)\n",
    "\n",
    "TRAIN_NEW_MODEL = False\n",
    "if TRAIN_NEW_MODEL:\n",
    "  extractor.train_extractor()\n",
    "  extractor.save_model()\n",
    "else:\n",
    "  extractor.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4354, 646)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_positives = (y_test.sum(dim=1) > 0).sum().item()\n",
    "test_negatives = (y_test.sum(dim=1) == 0).sum().item()\n",
    "test_positives,test_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.67%\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    486447\n",
      "           1       0.98      0.90      0.94     13553\n",
      "\n",
      "    accuracy                           1.00    500000\n",
      "   macro avg       0.99      0.95      0.97    500000\n",
      "weighted avg       1.00      1.00      1.00    500000\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_predictions = extractor.predict(X_test).view(-1)\n",
    "flatted_y_test = y_test.view(-1).cpu()\n",
    "\n",
    "print(f\"Test Accuracy: {(accuracy_score(flatted_y_test, y_test_predictions)*100):.2f}%\")\n",
    "print(f\"Classification Report: \\n{classification_report(flatted_y_test, y_test_predictions)}\")\n",
    "cm = confusion_matrix(flatted_y_test, y_test_predictions, normalize='pred')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[0,1])\n",
    "cmd.plot()\n",
    "print(\"Confusion Matrix:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T04:02:51.484972Z",
     "iopub.status.busy": "2024-11-16T04:02:51.484820Z",
     "iopub.status.idle": "2024-11-16T04:02:51.586294Z",
     "shell.execute_reply": "2024-11-16T04:02:51.585934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted headword: Gustav Vasa\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"Gustav Vasa, ursprungligen Gustav Eriksson,[2] enligt flera källor född 12 maj 1496, död 29 september 1560 på Tre Kronor i Stockholm.[3] var kung av Sverige 1523–1560 och riksföreståndare 1521–1523, under det pågående befrielsekriget. Hans makttillträde, inlett som ett uppror mot unionskungen Kristian II efter Stockholms blodbad, innebar slutet för Kalmarunionen. Gustav tillhörde Vasaätten, som genom\"\n",
    "encoded_input = tokenizer(input_sentence, return_tensors=\"pt\", padding = \"max_length\", max_length = 100, truncation = True)['input_ids'].to(device)\n",
    "\n",
    "output_mask = extractor.predict(encoded_input).view(-1)\n",
    "headword = encoded_input.cpu().view(-1)[torch.flatten(torch.nonzero(output_mask))]\n",
    "decoded_headword = tokenizer.decode(headword, skip_special_tokens=True)\n",
    "print(\"Predicted headword:\", decoded_headword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_editions():\n",
    "  tokenized_editions = []\n",
    "  for edition in datafiles.keys():\n",
    "    edition_data = \"\"\n",
    "    for file in datafiles.get(edition):\n",
    "      with open(f\"./dataset/NF_{edition}{file}.txt\", \"r\", encoding='utf-8') as fr:\n",
    "        edition_data += fr.read()\n",
    "        fr.close()\n",
    "    edition_data = re.sub(r\"<b>|</b>\", \"\", edition_data)\n",
    "    \n",
    "    splitted_paragraphs = re.split(r\"\\n\\n\", edition_data)\n",
    "    filterd_paragraphs = filter(lambda p: len(p) >= 10, splitted_paragraphs)\n",
    "    truncated_paragraphs = map(lambda p: p[:500] if len(p) > 500 else p, filterd_paragraphs)\n",
    "    \n",
    "    paragraphs = torch.stack(\n",
    "      [tokenizer(\n",
    "          p,\n",
    "          add_special_tokens=True, \n",
    "          padding='max_length',   \n",
    "          max_length=100,        \n",
    "          truncation=True,       \n",
    "          return_tensors='pt'  \n",
    "        )['input_ids'][0] \n",
    "        for p in tqdm(list(truncated_paragraphs))\n",
    "      ]).to(device)\n",
    "    tokenized_editions.append(paragraphs)\n",
    "  torch.save(tokenized_editions, './dataset/tokenized_editions.pth')\n",
    "  return tokenized_editions\n",
    "\n",
    "SHOULD_TOKENIZE_EDITIONS = False\n",
    "if SHOULD_TOKENIZE_EDITIONS:\n",
    "  editions = tokenize_editions()\n",
    "else:\n",
    "  editions = torch.load('./dataset/tokenized_editions.pth', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115574, 181361, 24591, 84814, 406340)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_editions():\n",
    "  db = {}\n",
    "  for ei, edition in enumerate(editions):\n",
    "    # Predict editions by batches:\n",
    "    edition_loader = DataLoader(edition, batch_size=19000, shuffle=False)\n",
    "    edition_predictions = torch.empty((0,100)).to(device)\n",
    "    for batch in tqdm(edition_loader, desc=f\"Predicting Edtion E{ei+1}\"):\n",
    "      batch_prediction = extractor.predict(batch).to(device)\n",
    "      edition_predictions = torch.cat((edition_predictions, batch_prediction))\n",
    "\n",
    "    # Filter away non-headword predictions:\n",
    "    predicted_input = edition[torch.unique(torch.nonzero(edition_predictions)[:, 0])]\n",
    "    predicted_masks = edition_predictions[torch.unique(torch.nonzero(edition_predictions)[:, 0])]\n",
    "    predicted_entries = []\n",
    "    entry_cnt = 0\n",
    "    for input, mask in tqdm(list(zip(predicted_input,predicted_masks)), desc=f\"Decoding   Edtion E{ei+1}\"):\n",
    "      decoded_headword = tokenizer.decode(input[mask.nonzero().flatten()], skip_special_tokens=True)\n",
    "      decoded_headword = re.sub(r\",\", \"\", decoded_headword)\n",
    "      if decoded_headword != \"\":\n",
    "        decoded_input = tokenizer.decode(input, skip_special_tokens=True)\n",
    "\n",
    "        if not re.search(r\"^Bild [\\diI]+\", decoded_input):\n",
    "          entry_cnt+=1\n",
    "          predicted_entries.append({\"entry_id\": f\"E{ei+1}_{entry_cnt}\", \"headword\": decoded_headword, \"definition\": decoded_input})\n",
    "          \n",
    "    db[f\"E{ei+1}\"] = predicted_entries\n",
    "\n",
    "  with open(\"./extracted_entries.json\", \"w\") as entry_json:\n",
    "    json.dump(db, entry_json, indent=2, ensure_ascii=False)\n",
    "    entry_json.close()\n",
    "\n",
    "def load_in_db():\n",
    "  try:\n",
    "    with open(\"./extracted_entries.json\", \"r\", encoding='utf-8') as entry_json_r:\n",
    "      db = json.load(entry_json_r)\n",
    "      entry_json_r.close()\n",
    "  except:\n",
    "    db = {}\n",
    "  return db\n",
    "\n",
    "PREDICT_EDITIONS = False\n",
    "if PREDICT_EDITIONS:\n",
    "  predict_editions()\n",
    "\n",
    "db = load_in_db()\n",
    "len(db['E1']), len(db['E2']), len(db['E3']), len(db['E4']), len(db['E1']) + len(db['E2']) + len(db['E3']) + len(db['E4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KB/bert-base-swedish-cased-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner_model = AutoModelForTokenClassification.from_pretrained(\"KB/bert-base-swedish-cased-ner\").to(device)\n",
    "\n",
    "def classify_entity(sentence, headword):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "      0 --> Other\\n\n",
    "      1 --> Location\\n\n",
    "      2 --> Person\n",
    "    \"\"\"\n",
    "    encoded_sentence = tokenizer(sentence,add_special_tokens=True,padding='max_length',max_length=100,truncation=True,return_tensors='pt').to(device)\n",
    "    encoded_headword = tokenizer(headword,add_special_tokens=True,padding='max_length',max_length=20,truncation=True,return_tensors='pt')['input_ids'][0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "      encoded_outputs = torch.argmax(ner_model(**encoded_sentence).logits, dim=2)\n",
    "\n",
    "    labels = encoded_outputs.flatten()[(encoded_headword > 4).nonzero()].flatten()\n",
    "    if 7 in labels and 9 in labels:\n",
    "      return 0\n",
    "    elif 7 in labels:\n",
    "      return 1\n",
    "    elif 9 in labels:\n",
    "      return 2\n",
    "    else:\n",
    "      return 0\n",
    "    \n",
    "def perform_NER():\n",
    "  for e in db:\n",
    "    entries = db[e]\n",
    "\n",
    "    for entry in tqdm(entries):\n",
    "      ner = classify_entity(entry['definition'], entry['headword'])\n",
    "      entry['type'] = ner\n",
    "    \n",
    "  with open(\"./ner_entries.json\", \"w\") as ner_json:\n",
    "    json.dump(db, ner_json, indent=2, ensure_ascii=False)\n",
    "    ner_json.close()\n",
    "\n",
    "PERFORM_NER = False\n",
    "if PERFORM_NER:\n",
    "  perform_NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Person'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Other', 'Location', 'Person'][classify_entity(input_sentence, decoded_headword)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
