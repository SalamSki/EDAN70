{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "Imports and define names of datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "datafiles= {\n",
    "  \"E1\" : [''],\n",
    "  \"E2\" : ['a', 'b'],\n",
    "  \"E3\" : [''],\n",
    "  \"E4\" : ['']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that extracts headwords out of \\<b\\> tags to build a headword dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_b_tag_dataset(datastring, next_chars = 500, verbose=False):\n",
    "  b_tag_dict = []\n",
    "\n",
    "  # BUILD POSITIVE \n",
    "  for match in tqdm(re.finditer(r\"((?<=<b>).+<\\/b>)(.*(?<=<b>).+<\\/b>)*\", datastring), disable=(not verbose)):\n",
    "    g1 = match.group(0)\n",
    "    matched_b_tag = re.sub(r\"</b>.*<b>|</b>\",\" \",g1).strip()\n",
    "    end_of_b_tag = match.end()  \n",
    "    \n",
    "    surrounding_text_match = re.search(r\"([^<]{1,\"+str(next_chars)+r\"})(?=<|$)\", datastring[end_of_b_tag:end_of_b_tag+next_chars])\n",
    "    surrounding_text = surrounding_text_match.group(0) if surrounding_text_match else \"\"\n",
    "\n",
    "    short_def = re.sub(r\"\\s+\", \" \", surrounding_text).strip()\n",
    "    if len(short_def) > 0:\n",
    "      b_tag_dict.append([f\"{matched_b_tag} {short_def}\", matched_b_tag])\n",
    "\n",
    "  # BUILD NEGATIVE\n",
    "  for match in tqdm(re.finditer(r\"(\\n\\n[^<]{10,500})(?=\\n|$|<)\", datastring), disable=(not verbose)):\n",
    "    g = match.group(0)\n",
    "    matched_text = re.sub(r\"\\s+\", \" \", g).strip()\n",
    "    b_tag_dict.append([matched_text, \"\"])\n",
    "\n",
    "  return b_tag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the headword datasets for the first and second editions (E1 \\& E2) where for each entry there is:\n",
    "  - Feature: A paragraph or piece of text that starts with a headword, followed by up to <i>next_chars</i> number of characters, default is 500.\n",
    "  - label: The headword at the beginning of the corresponding feature, empty string if feature wasn't a <i>\"headword\"</i> paragraph.\n",
    "\n",
    "Save results to json files:\n",
    "```json\n",
    "  [\"Lund, uppstad i Malmöhus län...beskaffenhet. I all\", \"Lund,\"]\n",
    "  [\"betjenade sig af rapporter från...till privatlifvet\", \"\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,edition in enumerate(['E1', 'E2']):\n",
    "\n",
    "  dataset = \"\"\n",
    "  for file in datafiles.get(edition):\n",
    "    with open(f\"./dataset/NF_{edition}{file}.txt\", \"r\", encoding='utf-8') as fr:\n",
    "      dataset += fr.read()\n",
    "      fr.close()\n",
    "      \n",
    "  b_tag_dict = build_b_tag_dataset(dataset, verbose=True)\n",
    "  print(f\"{edition} has {len(b_tag_dict):,} entries\")\n",
    "\n",
    "  with open(f\"./dataset/NF_{edition}_B.json\", \"w\") as b_json:\n",
    "    json.dump(b_tag_dict, b_json, indent=2, ensure_ascii=False)\n",
    "del i, edition, dataset, file, fr, b_tag_dict, b_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
